# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
This dataset contains data about marketing campaign a bank had and we seek to predict if clients would subscribe to a term deposit.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best performing model was one with score of 0.9117

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
primary_metric_config':"name": "Accuracy", "goal": "maximize
The data is a marketing data thhat comprices of 32950, 21
Random sampling, which supports discrete and continuous hyperparameters was used
The primary metric to optimize was accuracy and the the goal was to maximize.
Early termination policy was Bandit Policy and the parameter were slack_factor and evaluation_interval.
The algorithm is a two class classification to predict between two categories.

**What are the benefits of the parameter sampler you chose?**
Under random sampling, each member of the in the dataset carries an equal opportunity of being chosen as a part of the sampling process.
This removes bias in the representation of data which is important for drawing conclusions.

**What are the benefits of the early stopping policy you chose?**
The specified parameters are slack_factor(The ratio used to calculate the allowed distance from the best performing experiment run) and evaluation_interval(The frequency for applying the policy). Here the benefits could be seen in that any run that doesn't fall within the slack factor of the evaluation metric with respect to the best performing run will be terminated. This saves appreciable time and resources.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
Ensemble methods helps improve machine learning results by combining multiple models. I believe using ensemble methods allowed to produce better predictions compared to a single model.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
hyper parameter tuning with hyperdrive gave accuracy of 0.9115 while AML best performing model was 0.9171.
This difference is because of AML's ability to iteratively find the best hyperparameter values for the model.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
Bias in input data towards one class can affect the model accuracy. Handling this will be a huge improvement

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**

